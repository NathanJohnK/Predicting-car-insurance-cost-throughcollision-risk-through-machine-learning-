{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNf4vmO2VcFf"
      },
      "source": [
        "#Instructions\n",
        "\n",
        "This document is a template to help you get started and will mirror the work that you will do in modules 2, 3, 4 and 5 with the Taxi Trip dataset problem.\n",
        "\n",
        "You should save a copy of this in your Colab and change the name of the file to include your student number.\n",
        "\n",
        "Within this document there are comments to help you along and some boilerplate code that you can adjust to get you started but the code will be very similar to that found in the practice document.\n",
        "\n",
        "This document has the following sections and should be submitted with those in place:\n",
        "\n",
        "\n",
        "\n",
        "*   Title\n",
        "*   Introduction\n",
        "*   Module 2: Get the data\n",
        "*   Module 3: Basic statistics and visualisations\n",
        "*   Module 4: Regression models\n",
        "*   Module 5: Using the outcomes\n",
        "\n",
        "\n",
        "Enjoy and learn lots."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PB9gpS0nXrUP"
      },
      "source": [
        "# Problem: Can we accurately predict the number of collisions for any given day of the week?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHW3s-IPXtcw"
      },
      "source": [
        "##Introduction\n",
        "\n",
        "You work as a product owner for a car insurance company offering a daily insurance policy for car rentals.   \n",
        "\n",
        "The company operates in New York and wants to price its insurance to reflect collision risk and associated costs. It wants you to explore a new feature for development that will make better predictions about this. We will use New York traffic collision data to make estimates about the number of collisions on a given day.  \n",
        "\n",
        "For this you require weather data as there has been a link between weather and traffic collisions. The company is using data given to them by the emergency services.\n",
        "\n",
        "Note: You will be given a file entitled collisions_and_weather_data.csv testdata2019.csv. Due to Covid-19, all data since early 2020 has been fairly useless with respect to patterns. The company can see that the data has recently returned to full pre-pandemic levels and you will be provided data from 1st of January 2013 to 31st of December 2018 and the test data will be from 2019.\n",
        "\n",
        "Remember, you will have to put these files in your Google Drive."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x57j7i7HiUb4"
      },
      "source": [
        "## Module 2: Get the data\n",
        "\n",
        "This section contains boilerplate code. As long as you have uploaded your CSV files to your Google Drive, you can just run the cells as normal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zexfYuotmJLU"
      },
      "outputs": [],
      "source": [
        "# Import packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "#added seaborn as sns\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Vhy2CCQ0mKRB"
      },
      "outputs": [],
      "source": [
        "#set the size of our plots as they are a little small by default.\n",
        "plt.rcParams[\"figure.figsize\"] = (20,5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5nuwqVbmM6l",
        "outputId": "508ff868-4b45-4d1a-d772-94956e4bbd66"
      },
      "outputs": [],
      "source": [
        "# Link with your google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Pp0uARhqmRiz"
      },
      "outputs": [],
      "source": [
        "# get our collated taxi trip and weather data from google drive\n",
        "df = pd.read_csv('/content/gdrive/MyDrive/LBD_New_York_collisions_and_weather_data.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECoB1uvDdErO"
      },
      "source": [
        "Watch this...\n",
        "\n",
        "https://us06web.zoom.us/rec/play/eScR8cyO0tk9T3XOv77BlebssDgiKGjSDeYmmxwTmrs9g6A91Jego_OkpKS3mioa1oipCPrzCUAqt4xL.MHHOsmGFhlUio3Mp?canPlayFromShare=true&from=share_recording_detail&continueMode=true&componentName=rec-play&originRequestUrl=https%3A%2F%2Fus06web.zoom.us%2Frec%2Fshare%2FCV9YLZWgX7wLqGhaRSR-MNwtxOMawl4DrLxmnzQAHA6fmQgfL8BoTcKcjo57o1Wd.OfJN_SEUuQNECDAp\n",
        "\n",
        "Passcode: 1&Jim4@S\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "AjpJougrmaYj",
        "outputId": "5970220b-e86d-4881-a400-04bc1084ae80"
      },
      "outputs": [],
      "source": [
        "# Creating a dataframe to show the data\n",
        "# This is returns the first n rows for the object based on position. It is useful for quickly testing if your object has the right type of data in it.\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rG5AlY_oicTi"
      },
      "source": [
        "## Module 3: Basic statistics and visualisations SORT OUT lATER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UYNvEndMby8"
      },
      "source": [
        "Task is: Company wants to price its insurance to reflect collision risk and associated costs. It wants you to explore a new feature for development that will make better predictions about this.\n",
        "\n",
        "In this section, I am going to investigate the data using some basic stats and visualisations. I have weather date and information about the number of collisions per day.\n",
        "\n",
        "Specifically, I want to explore:\n",
        "1. Top level - are there more accidents on one day of the week compared to another?\n",
        "2. Are there more accidents in a particular month?\n",
        "3. Are there more accidents in colder conditions?\n",
        "\n",
        "My hypothesis is that: On some days, there are more crashes and this also depends on conditions too.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "sjL67GNCmi16",
        "outputId": "bc6deef2-015e-4c90-f79a-6468a4dc1314"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39msort_values([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmo\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mda\u001b[39m\u001b[38;5;124m\"\u001b[39m], ascending \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m)) \u001b[38;5;66;03m# order the data by year, month, day in ascending order.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m df\u001b[38;5;241m.\u001b[39mhead() \u001b[38;5;66;03m# check the data again by viewing the first 5 rows\u001b[39;00m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ],
      "source": [
        "df = df.sort_values([\"year\", \"mo\", \"da\"], ascending = (True, True, True)) # order the data by year, month, day in ascending order.\n",
        "df.head() # check the data again by viewing the first 5 rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "B06YRBcnmnYG",
        "outputId": "d304b8ac-d8b0-403c-c96c-5cd29219d12b"
      },
      "outputs": [],
      "source": [
        "df.describe()\n",
        "#The describe() method returns description of the data in the DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 594
        },
        "id": "7e3l45gsmujg",
        "outputId": "9c319c75-580b-403e-919d-2285ff568467"
      },
      "outputs": [],
      "source": [
        "corrMatrix = df.corr()\n",
        "# Creates correlation matrix which shows all the correlations we have\n",
        "sn.heatmap(corrMatrix, annot=True)\n",
        "#Makes a heatmap of the matrix\n",
        "plt.show()\n",
        "# Plots the above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "id": "mfUu8-V3P5F2",
        "outputId": "1349aa20-2d7c-4c87-ccef-a32236dab531"
      },
      "outputs": [],
      "source": [
        "# Filter correlations above 0.4\n",
        "corrMatrix_filtered = corrMatrix[(corrMatrix > 0.4) | (corrMatrix >= 0.2)]\n",
        "\n",
        "# Plot heatmap\n",
        "sns.heatmap(corrMatrix_filtered, annot=True)\n",
        "\n",
        "# Add title and axis labels\n",
        "plt.title('Correlation Heatmap (Correlations >= 0.2)')\n",
        "plt.xlabel('Features')\n",
        "plt.ylabel('Features')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Focussing mainly on correlations between Num_collisions and other variables\n",
        "\n",
        "# Interesting findings around min and max temperature but nothing really correlating. Temp and snow depth, as you'd expect\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jx5ivVxWexPH"
      },
      "source": [
        "**More weather bits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2QdPWShW11h"
      },
      "source": [
        "**Next section examines the basic statistics around the collisions per day**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "c8ecQhbra4i9",
        "outputId": "ec53dd5d-c876-4b81-8529-0dc17b4fff49"
      },
      "outputs": [],
      "source": [
        "# Group the data by the day of the week and calculate the sum of collisions for each day\n",
        "collisions_per_day = df.groupby('day')['NUM_COLLISIONS'].sum().reset_index()\n",
        "\n",
        "# Rename the columns for clarity\n",
        "collisions_per_day.columns = ['Day of the Week', 'Total Collisions']\n",
        "\n",
        "# Sort the table by total collisions in descending order\n",
        "collisions_per_day = collisions_per_day.sort_values(by='Total Collisions', ascending=False)\n",
        "\n",
        "# Display the table\n",
        "print(collisions_per_day)\n",
        "\n",
        "##Interesting - Friday as the most collisions, with Sunday the least - rush hour, commuting\n",
        "## so what's the connection between Friday and Sunday. Sunday is a quieter day, Friday busier. Don't have a time of day so can't look at this in more detail.\n",
        "##is there time data available?\n",
        "\n",
        "\n",
        "#Correlation between weather? Rainfall on a particular day? or by month?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "crt7s6QJWRpG",
        "outputId": "6f84f674-694e-4d0e-aa1f-a2d2612b4087"
      },
      "outputs": [],
      "source": [
        "sns.boxplot(x=df['day'], y=df['NUM_COLLISIONS'])\n",
        "plt.xlabel('Day of the Week')\n",
        "plt.ylabel('Number of Collisions')\n",
        "plt.title('Boxplot of Number of Collisions by Day of the Week')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "mqTBKCQGmzBP",
        "outputId": "5d382662-4dad-4451-f1fd-db6140dfbc64"
      },
      "outputs": [],
      "source": [
        "#Let's be really clear here - 'day' is refering to the day of the week.\n",
        "\n",
        "plt.ylim(0, 1300)\n",
        "plt.scatter(df.day, df.NUM_COLLISIONS)\n",
        "plt.title('Collisions per day of the week')\n",
        "plt.xlabel('Day of the week')\n",
        "plt.ylabel('Total collisions')\n",
        "\n",
        "plt.show()\n",
        "## code snippet is visualizing the relationship between the day and NUM_COLLISIONS columns from the DataFrame df using a scatter plot, with the y-axis limited to values between 0 and 1300.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "VmQchytQnFNL",
        "outputId": "671dc488-f8fe-418f-ae61-6b3e5f48cfeb"
      },
      "outputs": [],
      "source": [
        "plt.scatter(df.day, df.NUM_COLLISIONS, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "##This code creates a scatter plot using matplotlib's scatter function, representing the relationship between the day and NUM_COLLISIONS columns from the DataFrame df.\n",
        "## The parameter alpha=0.3 sets the transparency level of the markers to 0.3, making them slightly transparent.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lse_XLD4nI7_"
      },
      "source": [
        "There will be some analysis and repetition of processes here while trying to find linear relationships, such as cleaning the data and testing different years.\n",
        "\n",
        "The plot below is using the untouched dataframe **df**. You should change this to reflect any of the cleaning you have done."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QV5V3TaVjPco"
      },
      "source": [
        "Looking at collisions per year"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "ien2xe3Jj_io",
        "outputId": "50079972-4bf4-4690-8288-eead158ba982"
      },
      "outputs": [],
      "source": [
        "# Convert the 'collision_date' column to datetime format\n",
        "df['collision_date'] = pd.to_datetime(df['collision_date'])\n",
        "\n",
        "# Extract the year from the 'collision_date' column\n",
        "df['year'] = df['collision_date'].dt.year\n",
        "\n",
        "# Group the data by year and calculate the total collisions for each year\n",
        "collisions_per_year = df.groupby('year')['NUM_COLLISIONS'].sum().reset_index()\n",
        "\n",
        "# Plot the chart with a line of best fit\n",
        "sns.regplot(x='year', y='NUM_COLLISIONS', data=collisions_per_year, scatter_kws={\"s\": 100})\n",
        "\n",
        "# Add title and labels\n",
        "plt.title('Total Collisions Per Year')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Total Collisions')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "##Insight - collisions are growing year on year"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "EwFSjQkQnR2f",
        "outputId": "74e5642e-4937-46df-84af-efa4356f46df"
      },
      "outputs": [],
      "source": [
        "\n",
        "groups = df.groupby('year') # We group by year as we want to create a legend and make the visualisation clearer using colour.\n",
        "plt.ylim(0, 1300)\n",
        "for name, group in groups:\n",
        "    plt.plot(group.collision_date, group.NUM_COLLISIONS, marker='o', linestyle='', markersize=2, label=name)\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "print(\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5egt-Aq0i2wR"
      },
      "source": [
        "Collisions per day of the month? Compared across each month across all years?\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "RS2TszY_r9hF",
        "outputId": "997345d7-f76a-40e9-9be9-a351d7d00fd2"
      },
      "outputs": [],
      "source": [
        "# Assuming you have a DataFrame named df\n",
        "\n",
        "# Convert the 'collision_date' column to datetime format\n",
        "df['collision_date'] = pd.to_datetime(df['collision_date'])\n",
        "\n",
        "# Extract the month from the 'collision_date' column\n",
        "df['month'] = df['collision_date'].dt.month\n",
        "\n",
        "# Group the data by month and calculate the total collisions for each month\n",
        "collisions_per_month = df.groupby('month')['NUM_COLLISIONS'].sum().reset_index()\n",
        "\n",
        "# Plot the chart with a line of best fit\n",
        "sns.regplot(x='month', y='NUM_COLLISIONS', data=collisions_per_month, scatter_kws={\"s\": 100})\n",
        "\n",
        "# Customize x-axis labels\n",
        "plt.xticks(ticks=range(1, 13), labels=['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December'])\n",
        "\n",
        "# Add title and labels\n",
        "plt.title('Total Collisions Per Month')\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Total Collisions')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 894
        },
        "id": "2lofq9Gpsvye",
        "outputId": "73168e20-d26f-4103-dc27-dc843f17a331"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Assuming you have a DataFrame named df\n",
        "\n",
        "# Convert the 'collision_date' column to datetime format\n",
        "df['collision_date'] = pd.to_datetime(df['collision_date'])\n",
        "\n",
        "# Extract the month from the 'collision_date' column\n",
        "df['month'] = df['collision_date'].dt.month\n",
        "\n",
        "# Group the data by month and calculate the total collisions for each month\n",
        "collisions_per_month = df.groupby('month')['NUM_COLLISIONS'].sum().reset_index()\n",
        "\n",
        "# Plot the chart with a line of best fit\n",
        "sns.regplot(x='month', y='NUM_COLLISIONS', data=collisions_per_month, scatter_kws={\"s\": 100})\n",
        "\n",
        "# Add data labels (annotations)\n",
        "for i, row in collisions_per_month.iterrows():\n",
        "    plt.annotate(row['NUM_COLLISIONS'], (row['month'], row['NUM_COLLISIONS']), textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
        "\n",
        "# Customize x-axis labels\n",
        "plt.xticks(ticks=range(1, 13), labels=['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December'])\n",
        "\n",
        "# Add title and labels\n",
        "plt.title('Total Collisions Per Month')\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Total Collisions')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Anova\n",
        "from scipy.stats import f_oneway\n",
        "\n",
        "# Assuming collisions_per_month DataFrame contains data for each month\n",
        "# Perform ANOVA test\n",
        "f_statistic, p_value = f_oneway(df[df['month'] == 1]['NUM_COLLISIONS'],\n",
        "                                 df[df['month'] == 2]['NUM_COLLISIONS'],\n",
        "                                 df[df['month'] == 3]['NUM_COLLISIONS'],\n",
        "                                 df[df['month'] == 4]['NUM_COLLISIONS'],\n",
        "                                 df[df['month'] == 5]['NUM_COLLISIONS'],\n",
        "                                 df[df['month'] == 6]['NUM_COLLISIONS'],\n",
        "                                 df[df['month'] == 7]['NUM_COLLISIONS'],\n",
        "                                 df[df['month'] == 8]['NUM_COLLISIONS'],\n",
        "                                 df[df['month'] == 9]['NUM_COLLISIONS'],\n",
        "                                 df[df['month'] == 10]['NUM_COLLISIONS'],\n",
        "                                 df[df['month'] == 11]['NUM_COLLISIONS'],\n",
        "                                 df[df['month'] == 12]['NUM_COLLISIONS'])\n",
        "\n",
        "print(\"ANOVA F-statistic:\", f_statistic)\n",
        "print(\"P-value:\", p_value)\n",
        "\n",
        "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
        "\n",
        "# Define a dictionary to map month numbers to month names\n",
        "month_names = {\n",
        "    1: 'January',\n",
        "    2: 'February',\n",
        "    3: 'March',\n",
        "    4: 'April',\n",
        "    5: 'May',\n",
        "    6: 'June',\n",
        "    7: 'July',\n",
        "    8: 'August',\n",
        "    9: 'September',\n",
        "    10: 'October',\n",
        "    11: 'November',\n",
        "    12: 'December'\n",
        "}\n",
        "\n",
        "# Perform Tukey's HSD test\n",
        "tukey_results = pairwise_tukeyhsd(df['NUM_COLLISIONS'], df['month'])\n",
        "\n",
        "# Get significant differences\n",
        "significant_differences = tukey_results.summary().data\n",
        "\n",
        "# Convert the result to DataFrame\n",
        "significant_differences_df = pd.DataFrame(significant_differences[1:], columns=significant_differences[0])\n",
        "\n",
        "# Map month numbers to month names\n",
        "significant_differences_df['group1'] = significant_differences_df['group1'].astype(int).map(month_names)\n",
        "significant_differences_df['group2'] = significant_differences_df['group2'].astype(int).map(month_names)\n",
        "\n",
        "# Filter significant differences\n",
        "significant_differences_df = significant_differences_df[significant_differences_df['reject']]\n",
        "\n",
        "# Sort significant differences based on the mean difference (meandiff column)\n",
        "significant_differences_sorted = significant_differences_df.sort_values(by='meandiff')\n",
        "\n",
        "# Print significant differences\n",
        "print(significant_differences_sorted)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mVhhHfx08JQ"
      },
      "source": [
        "###Data cleaning###\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amWZUVBTMhRj"
      },
      "source": [
        "This section will present my process of cleaning/ trimming the data and the subsequent analysis and findings.\n",
        "\n",
        "Again 'Narrative' marks the narrative of the analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EW3vIVVc1r6P"
      },
      "outputs": [],
      "source": [
        "#Delete me!!! timestamp in video is 20:20\n",
        "\n",
        "# In this section, I am trimming the data to keep rows where number of collisions is greater than 350 but less than 900\n",
        "#This will help to trim the data down\n",
        "\n",
        "df_300000_cleaned = df[df[\"NUM_COLLISIONS\"] > 350] # Create a new dataframe keeping all datapoints where NUM_TRIPS are greater than 350000\n",
        "df_cleaned = df_300000_cleaned[df_300000_cleaned[\"NUM_COLLISIONS\"] < 900] # Using the new dataframe we just created, keep all datapoints where NUM_TRIPS are less than 600000\n",
        "\n",
        "# Narrative - ok so now have a fresh dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "oiAha6a-9XR_",
        "outputId": "4e92849b-3e5a-4a13-bb75-6a892425a67c"
      },
      "outputs": [],
      "source": [
        "#view the data\n",
        "\n",
        "df_cleaned.describe()\n",
        "#The describe() method returns description of the data in the DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "waaVZQCfHu98"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jynjP_YoLH07"
      },
      "source": [
        "### Annual differences ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyKPM_bFLQMf",
        "outputId": "1cb7ee22-0479-416b-c89c-6cfb45274f70"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'df_cleaned' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Check how many collisions  per year\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Grouping by 'YEAR' and summing 'NUM_COLLISIONS' for each year\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m collisions_per_year \u001b[38;5;241m=\u001b[39m \u001b[43mdf_cleaned\u001b[49m\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNUM_COLLISIONS\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Displaying the number of collisions per year\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of collisions per year:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_cleaned' is not defined"
          ]
        }
      ],
      "source": [
        "#Check how many collisions  per year\n",
        "\n",
        "# Grouping by 'YEAR' and summing 'NUM_COLLISIONS' for each year\n",
        "collisions_per_year = df_cleaned.groupby('year')['NUM_COLLISIONS'].sum()\n",
        "\n",
        "# Displaying the number of collisions per year\n",
        "print(\"Number of collisions per year:\")\n",
        "print(collisions_per_year)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "X4Tlus2SLuUX",
        "outputId": "a37bb37e-0ede-449d-f7cc-69724f6da7da"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Grouping by 'year' and summing 'NUM_COLLISIONS' for each year\n",
        "collisions_per_year = df_cleaned.groupby('year')['NUM_COLLISIONS'].sum()\n",
        "\n",
        "# Convert the series to a DataFrame for plotting\n",
        "collisions_per_year_df = collisions_per_year.reset_index()\n",
        "\n",
        "# Create a bar chart\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(collisions_per_year_df['year'], collisions_per_year_df['NUM_COLLISIONS'], color='skyblue')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Number of Collisions')\n",
        "plt.title('Number of Collisions Per Year')\n",
        "plt.xticks(collisions_per_year_df['year'])  # Ensure all years are displayed on the x-axis\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()\n",
        "\n",
        "# Narrative - ok clearly collisions are increasing, year on year"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cvfyihpb-Dt"
      },
      "source": [
        "### Analysis of each individual year###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hE-sYuU-dpmg",
        "outputId": "2f89cc84-f637-4586-c471-18c4aa92bdc3"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'df_cleaned' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m day_mapping \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m1\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMonday\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m2\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTuesday\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m3\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWednesday\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m4\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThursday\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m5\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFriday\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m6\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSaturday\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m7\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSunday\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Apply the day mapping to the 'day' column\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m df_cleaned\u001b[38;5;241m.\u001b[39mloc[:, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mday_mapped\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_cleaned\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mday\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(day_mapping)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Group by year and day of the week, then sum the number of collisions\u001b[39;00m\n\u001b[1;32m     10\u001b[0m collisions_per_day_per_year \u001b[38;5;241m=\u001b[39m df_cleaned\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mday_mapped\u001b[39m\u001b[38;5;124m'\u001b[39m])[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNUM_COLLISIONS\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mreset_index()\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_cleaned' is not defined"
          ]
        }
      ],
      "source": [
        "#Narrative - I am going to examine whether the number of collisions for each day of the week changes from year to year\n",
        "\n",
        "# Define a mapping for days of the week\n",
        "day_mapping = {1: 'Monday', 2: 'Tuesday', 3: 'Wednesday', 4: 'Thursday', 5: 'Friday', 6: 'Saturday', 7: 'Sunday'}\n",
        "\n",
        "# Apply the day mapping to the 'day' column\n",
        "df_cleaned.loc[:, 'day_mapped'] = df_cleaned['day'].map(day_mapping)\n",
        "\n",
        "# Group by year and day of the week, then sum the number of collisions\n",
        "collisions_per_day_per_year = df_cleaned.groupby(['year', 'day_mapped'])['NUM_COLLISIONS'].sum().reset_index()\n",
        "\n",
        "# Pivot the table to have years as rows and days of the week as columns\n",
        "collisions_per_day_per_year_pivot = collisions_per_day_per_year.pivot_table(index='year', columns='day_mapped', values='NUM_COLLISIONS', fill_value=0)\n",
        "\n",
        "# Display the resulting table\n",
        "print(collisions_per_day_per_year_pivot)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "H_CzIwf0itTg",
        "outputId": "73cae2c9-5d15-422e-dd0e-bfd36a73ada9"
      },
      "outputs": [],
      "source": [
        "# Interesting - let's look more closely at the data for Friday, across the years.\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Filter the data for Friday and Sunday\n",
        "friday_sunday_data = collisions_per_day_per_year[(collisions_per_day_per_year['day_mapped'] == 'Friday') | (collisions_per_day_per_year['day_mapped'] == 'Sunday')]\n",
        "\n",
        "# Create a scatterplot\n",
        "plt.scatter(friday_sunday_data['year'], friday_sunday_data['NUM_COLLISIONS'], c=friday_sunday_data['day_mapped'].map({'Friday': 'blue', 'Sunday': 'red'}))\n",
        "\n",
        "# Fit a linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(friday_sunday_data[['year']], friday_sunday_data['NUM_COLLISIONS'])\n",
        "\n",
        "# Predict values using the model\n",
        "predictions = model.predict(friday_sunday_data[['year']])\n",
        "\n",
        "# Plot the line of best fit\n",
        "plt.plot(friday_sunday_data['year'], predictions, color='black', linestyle='-')\n",
        "\n",
        "# Create a custom legend\n",
        "#plt.legend(['Line of Best Fit', 'Friday', 'Sunday'], loc='upper left')\n",
        "\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Number of Collisions')\n",
        "plt.title('Scatterplot of Collisions on Friday and Sunday with Line of Best Fit')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "## Narrative - interesting - the number of collisions on Friday increased between 2015 and 2016"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_WKFrUibfIl",
        "outputId": "b3f5ecab-5f98-4542-de34-df633a2698cd"
      },
      "outputs": [],
      "source": [
        "# Code to create a dataframe for each year\n",
        "\n",
        "df_2012 = df_cleaned[df_cleaned[\"year\"] == 2012] # no data\n",
        "df_2013 = df_cleaned[df_cleaned[\"year\"] == 2013]\n",
        "df_2014 = df_cleaned[df_cleaned[\"year\"] == 2014]\n",
        "df_2015 = df_cleaned[df_cleaned[\"year\"] == 2015]\n",
        "df_2016 = df_cleaned[df_cleaned[\"year\"] == 2016]\n",
        "df_2017 = df_cleaned[df_cleaned[\"year\"] == 2017]\n",
        "df_2018 = df_cleaned[df_cleaned[\"year\"] == 2018]\n",
        "\n",
        "df_2013.describe()\n",
        "\n",
        "\n",
        "print('2013', df_2013['day'].count())\n",
        "print('2014', df_2014['day'].count())\n",
        "print('2015', df_2015['day'].count())\n",
        "print('2016', df_2016['day'].count())\n",
        "print('2017', df_2017['day'].count())\n",
        "print('2018', df_2018['day'].count())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "0-2LyIu7eSab",
        "outputId": "369f8144-7f6c-4ce2-b3d6-05bc15f1c754"
      },
      "outputs": [],
      "source": [
        "# Narrative - I am going to start with a simple table to show total collisions across year, by day\n",
        "\n",
        "day_mapping = {1: 'Monday', 2: 'Tuesday', 3: 'Wednesday', 4: 'Thursday', 5: 'Friday', 6: 'Saturday', 7: 'Sunday'}\n",
        "collisions_per_day_per_year['day'] = collisions_per_day_per_year['day'].map(day_mapping)\n",
        "collisions_per_day_per_year_pivot = collisions_per_day_per_year.pivot_table(index='year', columns='day', values='collisions_count', fill_value=0)\n",
        "print(collisions_per_day_per_year_pivot)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "_qifuziEblQp",
        "outputId": "9222f340-f0ac-4933-f1b0-32baeeba9aad"
      },
      "outputs": [],
      "source": [
        "#Creating a plot of 2013 data\n",
        "\n",
        "day_labels = ['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday']\n",
        "plt.scatter(df_2013['day'].map(lambda x: day_labels[x - 1]), df_2013['NUM_COLLISIONS'], alpha=0.3)\n",
        "plt.xlabel('Day of the Week')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlP0jy7TLZ3m"
      },
      "source": [
        "### Weekly differences ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gz0SV-2XNZ6F"
      },
      "source": [
        "Here I am going to examine the weekly differences, or the collisions occuring per day"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gS5mem5jOSkB",
        "outputId": "ba10b52b-6ecd-45bc-dab1-cb1c62b04ef0"
      },
      "outputs": [],
      "source": [
        "# Assuming df_cleaned contains the necessary data\n",
        "\n",
        "# Grouping data by day and summing up the collisions\n",
        "total_collisions_per_day = df_cleaned.groupby('day')['NUM_COLLISIONS'].sum()\n",
        "\n",
        "# Creating a DataFrame to represent the data\n",
        "table_data = pd.DataFrame({\n",
        "    'Day of the Week': ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'],\n",
        "    'Total Collisions': total_collisions_per_day.values\n",
        "})\n",
        "\n",
        "# Displaying the table\n",
        "print(table_data)\n",
        "\n",
        "## Second table shows the data arranged from highest number of collisions to lowest number of collisions\n",
        "\n",
        "total_collisions_per_day = df_cleaned.groupby('day')['NUM_COLLISIONS'].sum()\n",
        "\n",
        "table_data = pd.DataFrame({\n",
        "    'Day of the Week': ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'],\n",
        "    'Total Collisions': total_collisions_per_day.values\n",
        "})\n",
        "\n",
        "table_data = table_data.sort_values(by='Total Collisions', ascending=False)\n",
        "\n",
        "print(table_data)\n",
        "\n",
        "# Narrative - clearly, as the second table shows, most collisions occur on a Friday, with least on a Sunday. Seems to make sense.\n",
        "# Narrative - Correlations can explore this more."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McLFh5wTORt3"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "yjqo8Jvz2-6M",
        "outputId": "27562e51-993d-4728-bc75-e4969e698efa"
      },
      "outputs": [],
      "source": [
        "# Narrative: This plit is just a simple way of showing the data in the tables.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set the y-axis limit\n",
        "plt.ylim(0, 1000)\n",
        "\n",
        "# Define the day labels\n",
        "day_labels = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
        "\n",
        "# Plot the scatter plot\n",
        "plt.scatter(df_cleaned.day, df_cleaned.NUM_COLLISIONS, alpha=0.3)\n",
        "\n",
        "# Set the axis titles\n",
        "plt.xlabel('Day of the Week')\n",
        "plt.ylabel('Total Collisions')\n",
        "\n",
        "# Set the x-axis tick labels\n",
        "plt.xticks(range(1, 8), day_labels)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n",
        "\n",
        "#Narrative - the chart shows the same pattern as the tables above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-I7Cu1r79xT1"
      },
      "outputs": [],
      "source": [
        "# do comparison of the cleaned data (df_cleaned) vs original data using plots\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxFtLOSAvJiM"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8yUtsm8LApbS",
        "outputId": "7f73e480-df46-4e99-8776-47a5875df9b4"
      },
      "outputs": [],
      "source": [
        "#Code is examining the num collisions per week, with and without the alpha.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set the y-axis limit for the first plot\n",
        "plt.ylim(0, 1000)\n",
        "\n",
        "# Plot the scatter plot for the first plot\n",
        "plt.scatter(df_cleaned.day, df_cleaned.NUM_COLLISIONS)\n",
        "\n",
        "# Set the axis titles for the first plot\n",
        "plt.xlabel('Day of the Week (1 = Monday, 7 = Sunday)')\n",
        "plt.ylabel('Total Collisions')\n",
        "\n",
        "#Titles\n",
        "plt.title('Collisions per day of the week - trimmed data - without Alpha - limit 1000')\n",
        "plt.xlabel('Day of the week')\n",
        "plt.ylabel('Total collisions')\n",
        "\n",
        "# Show the first plot\n",
        "plt.show()\n",
        "\n",
        "### Second plot ###\n",
        "\n",
        "# Set the y-axis limit for the second plot\n",
        "plt.ylim(0, 1300)\n",
        "\n",
        "# Plot the scatter plot for the second plot\n",
        "plt.scatter(df_cleaned.day, df_cleaned.NUM_COLLISIONS, alpha=0.3)\n",
        "\n",
        "# Set the title and axis titles for the second plot\n",
        "plt.title('Collisions per day of the week - trimmed data - with Alpha - limit 1300')\n",
        "plt.xlabel('Day of the week')\n",
        "plt.ylabel('Total collisions')\n",
        "\n",
        "# Show the second plot\n",
        "plt.show()\n",
        "\n",
        "#Narrative - not a huge difference observed when comparing the plots.\n",
        "\n",
        "#In the final plot, I will adjust the alpha even lower\n",
        "\n",
        "# Set the y-axis limit for the third plot\n",
        "plt.ylim(0, 900)\n",
        "\n",
        "# Plot the scatter plot for the third plot\n",
        "plt.scatter(df_cleaned.day, df_cleaned.NUM_COLLISIONS, alpha=0.3)\n",
        "\n",
        "# Set the title and axis titles for the third plot\n",
        "plt.title('Collisions per day of the week - trimmed data - with Alpha - limit 900')\n",
        "plt.xlabel('Day of the week')\n",
        "plt.ylabel('Total collisions')\n",
        "\n",
        "# Show the second plot\n",
        "plt.show()\n",
        "\n",
        "# Narrative - that didn't appear to make a huge amount of difference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "id": "5S-0xuvha1ks",
        "outputId": "27dbde11-8d81-458e-8563-0360ebea4816"
      },
      "outputs": [],
      "source": [
        "day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
        "df_cleaned.boxplot(column='NUM_COLLISIONS', by='day', grid=True, positions=range(7), figsize=(10,6))\n",
        "plt.xticks(range(7), day_order)\n",
        "plt.xlabel('Day of the Week')\n",
        "plt.ylabel('Number of Collisions')\n",
        "plt.title('Boxplot of Number of Collisions by Day')\n",
        "plt.show()\n",
        "\n",
        "#Again, data shows the same thing - more collisions on Friday"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4_Bda8GZKE1"
      },
      "source": [
        "### Summary ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bRhOTAqdZDrA"
      },
      "outputs": [],
      "source": [
        "### Summary###\n",
        "\n",
        "### Narrative: Key findings thus far\n",
        "# 1. More collisions happen on a Friday, compared to a Sunday, with a dip between 2015 and 2016\n",
        "# 2. Data trimming does not appear to affect the trend\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zYSCsAvK7Z2"
      },
      "source": [
        "### Correlations of cleaned data ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "WoZS19XA9WdV",
        "outputId": "74fd5c74-4fb5-439d-bbe6-d53a41f8efe1"
      },
      "outputs": [],
      "source": [
        "#Next section will explore correlations of the cleaned data - all correlations, then trimmed correlations\n",
        "\n",
        "corrMatrix = df_cleaned.corr()\n",
        "# Creates correlation matrix which shows all the correlations we have\n",
        "sn.heatmap(corrMatrix, annot=True)\n",
        "#Makes a heatmap of the matrix\n",
        "plt.show()\n",
        "# Plots the above\n",
        "\n",
        "# Narrative - Interesting correlation - negative correlation of collisions and day.\n",
        "# cont. This means that, as the week progresses, the number of collisions decreases. This supports the pattern which is shown in the data. This is only a weak correlation however.\n",
        "# The same finding is true of number of collisions and year - as time increases, so does the number of collisions\n",
        "\n",
        "#Narrative - interesting correlations between weather data and number of collisions - certainly something to explore later.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G18BV_tS7XpN"
      },
      "outputs": [],
      "source": [
        "#Narrative - ok now I am going to transform the data, so that Sunday becomes Monday and compare across\n",
        "\n",
        "# Make a copy of the DataFrame to ensure you're working with the original\n",
        "df_switched = df_cleaned.copy()\n",
        "\n",
        "# Shift the days: Sunday becomes Monday\n",
        "df_switched.loc[df_switched['day'] == 7, 'day'] = 1\n",
        "df_switched.loc[df_switched['day'] < 7, 'day'] += 1\n",
        "\n",
        "print(\"it worked\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xMCRY35kxx4A"
      },
      "outputs": [],
      "source": [
        "corrMatrix = df_switched.corr()\n",
        "# Creates correlation matrix which shows all the correlations we have\n",
        "sn.heatmap(corrMatrix, annot=True)\n",
        "#Makes a heatmap of the matrix\n",
        "plt.show()\n",
        "# Plots the above\n",
        "\n",
        "# Narrative - Interesting correlation.\n",
        "\n",
        "#Narrative cont- there is now a very small but positive correlation between the number of collisions and the day and a stronger correlation between num of collisions and month\n",
        "\n",
        "#Interestingly, there are several correlations between weather variables such as temp and dewp - further analysis will explore these\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "binEiZo7PWHd"
      },
      "source": [
        "###Transforming days of the week###\n",
        "\n",
        "## In next section, the *code* will explore what changing day of week does###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iy18eXd_9XNE",
        "outputId": "8430f2bb-50c4-4316-db42-7ccca164e14f"
      },
      "outputs": [],
      "source": [
        "##Transform the data, so that Sunday becomes Monday and compare across\n",
        "\n",
        "df_2013_copy = df_2013.copy()  # Make a copy of the DataFrame to ensure you're working with the original\n",
        "df_2013_copy.loc[df_2013_copy['day'] > 0, 'day'] = df_2013_copy['day'] + 1\n",
        "df_2013_copy.loc[df_2013_copy['day'] == 8, 'day'] = 1\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "day_labels = ['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday']\n",
        "\n",
        "plt.scatter(df_2013_copy['day'], df_2013_copy['NUM_COLLISIONS'], alpha=0.3)\n",
        "plt.xlabel('Day of the Week')\n",
        "plt.ylabel('Number of Collisions')\n",
        "plt.title('Scatterplot of Number of Collisions in 2013')\n",
        "plt.xticks(range(1, 8), day_labels)\n",
        "plt.show()\n",
        "\n",
        "#now check the same data for 2014 and 2015\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# For 2014\n",
        "df_2014_copy = df_2014.copy()  # Make a copy of the DataFrame to ensure you're working with the original\n",
        "df_2014_copy.loc[df_2014_copy['day'] > 0, 'day'] = df_2014_copy['day'] + 1\n",
        "df_2014_copy.loc[df_2014_copy['day'] == 8, 'day'] = 1\n",
        "\n",
        "# Scatter plot for 2014\n",
        "plt.scatter(df_2014_copy['day'], df_2014_copy['NUM_COLLISIONS'], alpha=0.3)\n",
        "plt.xlabel('Day of the Week')\n",
        "plt.ylabel('Number of Collisions')\n",
        "plt.title('Scatterplot of Number of Collisions in 2014')\n",
        "plt.xticks(range(1, 8), day_labels)\n",
        "plt.show()\n",
        "\n",
        "# For 2015\n",
        "df_2015_copy = df_2015.copy()  # Make a copy of the DataFrame to ensure you're working with the original\n",
        "df_2015_copy.loc[df_2015_copy['day'] > 0, 'day'] = df_2015_copy['day'] + 1\n",
        "df_2015_copy.loc[df_2015_copy['day'] == 8, 'day'] = 1\n",
        "\n",
        "# Scatter plot for 2015\n",
        "plt.scatter(df_2015_copy['day'], df_2015_copy['NUM_COLLISIONS'], alpha=0.3)\n",
        "plt.xlabel('Day of the Week')\n",
        "plt.ylabel('Number of Collisions')\n",
        "plt.title('Scatterplot of Number of Collisions in 2015')\n",
        "plt.xticks(range(1, 8), day_labels)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FG-WM_UQ2uhj",
        "outputId": "156bef21-0f2a-4327-e7bb-03f4b25bc405"
      },
      "outputs": [],
      "source": [
        "#Next section will explore correlations of the cleaned data - all correlations, then trimmed correlations\n",
        "\n",
        "#2013 data\n",
        "\n",
        "corrMatrix = df_2013_copy.corr()\n",
        "# Creates correlation matrix which shows all the correlations we have\n",
        "sn.heatmap(corrMatrix, annot=True)\n",
        "#Makes a heatmap of the matrix\n",
        "plt.show()\n",
        "# Plots the above\n",
        "\n",
        "# 2014 data #\n",
        "\n",
        "corrMatrix = df_2014_copy.corr()\n",
        "# Creates correlation matrix which shows all the correlations we have\n",
        "sn.heatmap(corrMatrix, annot=True)\n",
        "#Makes a heatmap of the matrix\n",
        "plt.show()\n",
        "# Plots the above\n",
        "\n",
        "# 2015 data #\n",
        "\n",
        "corrMatrix = df_2015_copy.corr()\n",
        "# Creates correlation matrix which shows all the correlations we have\n",
        "sn.heatmap(corrMatrix, annot=True)\n",
        "#Makes a heatmap of the matrix\n",
        "plt.show()\n",
        "# Plots the above\n",
        "\n",
        "## Narrative\n",
        "\n",
        "#Overall, no obvious correlations between number of collisions and year.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEgOF-NHE0Bi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "DaAP2kAWPkX9",
        "outputId": "c8a2b1aa-6120-41cb-f8ba-ce7e657dcfc4"
      },
      "outputs": [],
      "source": [
        "#Timestamp 27 mins in\n",
        "\n",
        "#Code to transform days of the week\n",
        "\n",
        "df_2013_copy = df_2013.copy()  # Make a copy of the DataFrame to ensure you're working with the original\n",
        "\n",
        "# Shift the days of the week\n",
        "df_2013_copy.loc[df_2013_copy['day'] > 0, 'day'] = df_2013_copy['day'] + 2\n",
        "\n",
        "# Handle the wrap-around for days that exceed 7\n",
        "df_2013_copy['day'] = df_2013_copy['day'] % 7\n",
        "\n",
        "# Check scatterplot of 2013 data\n",
        "day_labels = ['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday']\n",
        "plt.scatter(df_2013_copy['day'].map(lambda x: day_labels[x - 1]), df_2013_copy['NUM_COLLISIONS'], alpha=0.3)\n",
        "plt.xlabel('Day of the Week')\n",
        "plt.show()\n",
        "\n",
        "print(\"Data transformed\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPKKJdrtHNPj"
      },
      "source": [
        "###Annual patterns###\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cNJN0eRrYBHP"
      },
      "outputs": [],
      "source": [
        "# Narrative - this section will explore seasonal and annual differences\n",
        "\n",
        "#Temperature, max and min appeared to correlate so let's explore those\n",
        "\n",
        "# As a reminder\n",
        "#max – Maximum temperature reported during the day in Fahrenheit to tenths. (The time of the maximum temperature report varies by country and region so this will sometimes not be the maximum for the calendar day.) Missing = 9999.9.\n",
        "#min – Minimum temperature reported during the day in Fahrenheit to tenths. (The time of the minimum temperature report varies by country and region so this will sometimes not be the minimum for the calendar day.) Missing = 9999.9.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "ghJxT1EkgY1-",
        "outputId": "867937d4-3d5c-413f-c5ed-58373e65405f"
      },
      "outputs": [],
      "source": [
        "#Check data structure\n",
        "df_2013.describe()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOUJIUnSJ0BM"
      },
      "outputs": [],
      "source": [
        "#First examine slp (Mean sea level pressure for the day in millibars to tenth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "RMy1qasAgYz5",
        "outputId": "47b1af5d-aa4b-4aad-e2a1-83a8437c19b2"
      },
      "outputs": [],
      "source": [
        "#Narrative - let's first look at 2013 data\n",
        "\n",
        "plt.ylim(0, 1000)\n",
        "plt.scatter(df_2013.temp, df_2013.NUM_COLLISIONS)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4biAp3smh4E_"
      },
      "source": [
        "### Create a new dataframe for regression analysis###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FvBn5EECrHsa"
      },
      "outputs": [],
      "source": [
        "df_2012 = df_cleaned[df_cleaned[\"year\"] == 2012]\n",
        "df_2012.loc[df_2012['day'] > 0, 'day'] = df_2012['day']+1 # change all days by adding 1.\n",
        "\n",
        "df_2012.loc[df_2012['day'] == 8, 'day'] = 1 # change days that equal 8 to day 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZBA85dsrWK2"
      },
      "outputs": [],
      "source": [
        "# Filter data for the year 2013\n",
        "df_2013 = df_cleaned[df_cleaned[\"year\"] == 2013].copy()\n",
        "\n",
        "# Increment all days by 1\n",
        "df_2013.loc[df_2013['day'] > 0, 'day'] += 1\n",
        "\n",
        "# Change days that are equal to 8 to 1\n",
        "df_2013.loc[df_2013['day'] == 8, 'day'] = 1\n",
        "\n",
        "\n",
        "# Filter data for the year 2014\n",
        "df_2014 = df_cleaned[df_cleaned[\"year\"] == 2014].copy()\n",
        "\n",
        "# Increment all days by 1\n",
        "df_2014.loc[df_2014['day'] > 0, 'day'] += 1\n",
        "\n",
        "# Change days that are equal to 8 to 1\n",
        "df_2014.loc[df_2014['day'] == 8, 'day'] = 1\n",
        "\n",
        "# Filter data for the year 2015\n",
        "df_2015 = df_cleaned[df_cleaned[\"year\"] == 2015].copy()\n",
        "\n",
        "# Increment all days by 1\n",
        "df_2015.loc[df_2015['day'] > 0, 'day'] += 1\n",
        "\n",
        "# Change days that are equal to 8 to 1\n",
        "df_2015.loc[df_2015['day'] == 8, 'day'] = 1\n",
        "\n",
        "# Filter data for the year 2016\n",
        "df_2016 = df_cleaned[df_cleaned[\"year\"] == 2016].copy()\n",
        "\n",
        "# Increment all days by 1\n",
        "df_2016.loc[df_2016['day'] > 0, 'day'] += 1\n",
        "\n",
        "# Change days that are equal to 8 to 1\n",
        "df_2016.loc[df_2016['day'] == 8, 'day'] = 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "yYsOoAUokSOV",
        "outputId": "2fc7a213-2e2a-4875-dc05-0ccc68ee78f0"
      },
      "outputs": [],
      "source": [
        "all_years = [df_2013, df_2014, df_2015, df_2016]\n",
        "df_final = pd.concat(all_years)\n",
        "print(df_final[\"day\"].count())\n",
        "\n",
        "df_final.head()\n",
        "print (\"ran this!\")\n",
        "\n",
        "df_final.describe()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gdDGowPiFb1",
        "outputId": "6f81dd5b-51b8-429b-9108-ebb94fdef8e5"
      },
      "outputs": [],
      "source": [
        "# Check if 'pickup_date' column exists\n",
        "if 'pickup_date' in df_final.columns:\n",
        "    # Convert 'pickup_date' to string data type\n",
        "    df_final['pickup_date'] = df_final['pickup_date'].astype(str)\n",
        "\n",
        "    # Create a new column with values the same as pickup_date\n",
        "    df_final['pickup_date_no_year'] = df_final['pickup_date']\n",
        "\n",
        "    # Remove year from the string for 2009 - 2013\n",
        "    df_final['pickup_date_no_year'] = df_final['pickup_date_no_year'].str.replace('2009-', '')\n",
        "    df_final['pickup_date_no_year'] = df_final['pickup_date_no_year'].str.replace('2010-', '')\n",
        "    df_final['pickup_date_no_year'] = df_final['pickup_date_no_year'].str.replace('2011-', '')\n",
        "    df_final['pickup_date_no_year'] = df_final['pickup_date_no_year'].str.replace('2012-', '')\n",
        "    df_final['pickup_date_no_year'] = df_final['pickup_date_no_year'].str.replace('2013-', '')\n",
        "else:\n",
        "    print(\"Error: 'pickup_date' column does not exist in DataFrame.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "aZi1XsiDinqJ",
        "outputId": "91d02171-3550-4cb3-a563-3489599a649f"
      },
      "outputs": [],
      "source": [
        "df_final.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "619TmMLNVeQd"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "89eXkRTTVkO6",
        "outputId": "ea3a8db6-ff75-4c3f-f80f-641826ef6a38"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "# check out this plot\n",
        "groups = df_final.groupby('year') # We group by year as we want to create a legend and make the visualization clearer using color.\n",
        "plt.ylim(0, 1480)\n",
        "\n",
        "for name, group in groups:\n",
        "    plt.plot(group.da, group.NUM_COLLISIONS, marker='o', linestyle='', markersize=2, label=name)\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "# Adding axis titles\n",
        "plt.xlabel('Day of the Year')\n",
        "plt.ylabel('Number of Collisions')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvsuI3VFiijI"
      },
      "source": [
        "### Regression models###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3E2w2GbPsHO"
      },
      "outputs": [],
      "source": [
        "#Narrative - clearly temperature an important variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNXADC_Innqy",
        "outputId": "735b1e8d-31e9-4da4-d2a9-6f8789391fb3"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9iw5xUuV7Oa"
      },
      "outputs": [],
      "source": [
        "df_final_linear.isna().sum()\n",
        "l\n",
        "df_final_linear = df_final_linear.dropna()\n",
        "\n",
        "li\n",
        "#The second line removes all rows with any missing values from the DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aW3Or1qMXaKA",
        "outputId": "764a1be4-9940-47f2-d800-bab53dbfdfcb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ewFpfznxXrbL"
      },
      "outputs": [],
      "source": [
        "#Narrative - now I want to make a very simple model, with just one single input (days) and one output (NUM_COLLISIONS). So, let's create a dataframe.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6RiUziN8Xv0-",
        "outputId": "9c48567c-d313-43fa-b750-6b5b294677d1"
      },
      "outputs": [],
      "source": [
        "one_input_data = [df_final[\"day\"], df_final[\"NUM_COLLISIONS\"]] # create an array of all values for day and all values for NUM_TRIPS in two columns\n",
        "headers = [\"day\", \"NUM_COLLISIONS\"] # declare the titles of our input and output. As you can see day is first and NUM_TRIPS is second and they correspond to the line above\n",
        "df_one_input = pd.concat(one_input_data, axis=1, keys=headers) # Bring these two arrays together to make a new dataframe\n",
        "df_one_input.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0urf--WbYfOY"
      },
      "outputs": [],
      "source": [
        "# ok now to train model\n",
        "\n",
        "train_dataset = df_one_input.sample(frac=0.8, random_state=0)\n",
        "test_dataset = df_one_input.drop(train_dataset.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "RZY-wi8eYp7j",
        "outputId": "ec9c4966-ce37-4a81-928b-09000eed3ace"
      },
      "outputs": [],
      "source": [
        "# now check it's all in there and working ok\n",
        "train_dataset.describe()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "bdpWsMiDYzlF",
        "outputId": "0e68bb37-ccdb-4879-c18a-7b02ab47937e"
      },
      "outputs": [],
      "source": [
        "test_dataset.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2wsF-h5_Y7Qg"
      },
      "outputs": [],
      "source": [
        "train_features = train_dataset.copy()\n",
        "test_features = test_dataset.copy()\n",
        "\n",
        "train_labels = train_features.pop('NUM_COLLISIONS')\n",
        "test_labels = test_features.pop('NUM_COLLISIONS')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n3KcNRZVZKBf"
      },
      "outputs": [],
      "source": [
        "scale_factor = 1000000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AywRrpB3ZO4J"
      },
      "outputs": [],
      "source": [
        "train_labels = train_labels/scale_factor\n",
        "test_labels = test_labels/scale_factor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tCC6rqmZaBH",
        "outputId": "6ad3699f-ff34-42da-ffac-b937a11527b8"
      },
      "outputs": [],
      "source": [
        "print(train_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stHrQhmqZl6x"
      },
      "source": [
        "Here is our process for linear regression with one input value (day) and one output value (NUM_TRIPS).\n",
        "\n",
        "Training a model with tf.keras typically starts by defining the model architecture. We will use a tf.keras.Sequential model which represents a sequence of steps.\n",
        "\n",
        "There are two steps in your single-variable linear regression model:\n",
        "\n",
        "    Normalise the 'day' input features using the tf.keras.layers.Normalization preprocessing layer.\n",
        "    Apply a linear transformation (y = mx + c) to produce one output using a linear layer (tf.keras.layers.Dense).\n",
        "\n",
        "The number of inputs can either be set by the input_shape argument, or automatically when the model is run for the first time.\n",
        "\n",
        "First, we create a NumPy array made of the 'day' features. Then, instantiate the tf.keras.layers.Normalization and fit its state to the day data.\n",
        "\n",
        "I mentioned earlier that we want to normalise our features (the input variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sis_UDZLZqjQ",
        "outputId": "eb868db9-05f4-4890-a59a-f44c393dff1a"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Assuming train_features is your training data\n",
        "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
        "normalizer.adapt(np.array(train_features))\n",
        "\n",
        "first = np.array(train_features[:1])\n",
        "\n",
        "# Print the first example before and after normalization\n",
        "with np.printoptions(precision=2, suppress=True):\n",
        "    print('First example:', first)\n",
        "    print()\n",
        "    print('Normalized:', normalizer(first).numpy())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5B03SlBBaHMA"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Assuming train_features is your DataFrame and 'day' is one of its columns\n",
        "day = np.array(train_features['day'])\n",
        "\n",
        "# Define and adapt the Normalization layer\n",
        "day_normalizer = tf.keras.layers.Normalization(input_shape=[1,], axis=None)\n",
        "day_normalizer.adapt(day)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "begofJ8Maa10",
        "outputId": "1a9e2262-bca7-4cf2-9175-4ba004f1dc3a"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Assuming day_normalizer is already defined as in your previous code\n",
        "# Define the model\n",
        "day_model = tf.keras.Sequential([\n",
        "    day_normalizer,\n",
        "    tf.keras.layers.Dense(units=1)  # accessing Dense layer through tf.keras.layers\n",
        "])\n",
        "\n",
        "# Print model summary\n",
        "day_model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "em4qe8npavwT",
        "outputId": "3b60d84a-3ee5-4b93-af00-cddd591d41d2"
      },
      "outputs": [],
      "source": [
        "day_model.predict(day[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k00DqDjIa2pS",
        "outputId": "172eec95-3a08-480e-c117-c6d40d0d374f"
      },
      "outputs": [],
      "source": [
        "day_model.compile(\n",
        "    optimizer=tf.optimizers.Adam(learning_rate=0.1),\n",
        "    loss='mean_absolute_error')\n",
        "\n",
        "print(\"It worked\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MCSJ0x42bJza"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbJaLJdgbLTg"
      },
      "source": [
        "Next we will use Keras model.fit to execute the training for 100 epochs.\n",
        "\n",
        "    List item\n",
        "    List item\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdBmwZTAbM-2",
        "outputId": "8ce56438-78a2-4eea-eb6c-d7828646fa1a"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "history = day_model.fit(\n",
        "    train_features['day'],\n",
        "    train_labels,\n",
        "    epochs=100,\n",
        "    # Suppress logging.\n",
        "    verbose=0,\n",
        "    # Calculate validation results on 20% of the training data.\n",
        "    validation_split = 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "m95xVtpObWyu",
        "outputId": "0907a25e-1310-4742-9e97-e1d8ce0bb273"
      },
      "outputs": [],
      "source": [
        "hist = pd.DataFrame(history.history)\n",
        "hist['epoch'] = history.epoch\n",
        "hist.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OuwfxkB8ba7I"
      },
      "outputs": [],
      "source": [
        "def plot_loss(history):\n",
        "  plt.plot(history.history['loss'], label='loss')\n",
        "  plt.plot(history.history['val_loss'], label='val_loss')\n",
        "  plt.ylim([0, 0.2])\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Error [NUM_TRIPS]')\n",
        "  plt.legend()\n",
        "  plt.grid(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "H2RTTxE1bdZy",
        "outputId": "e022238f-fe11-4894-9a0c-bc05656e90da"
      },
      "outputs": [],
      "source": [
        "plot_loss(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQ9DMh-ocOm1"
      },
      "outputs": [],
      "source": [
        "test_results = {}\n",
        "\n",
        "test_results['day_model'] = day_model.evaluate(\n",
        "    test_features['day'],\n",
        "    test_labels, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qi42J_Q1cR95",
        "outputId": "83658d5f-a4ea-4367-dab4-262ee192f093"
      },
      "outputs": [],
      "source": [
        "x = tf.linspace(1, 7, 8)\n",
        "y = day_model.predict(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRDUYwSjcW3W"
      },
      "outputs": [],
      "source": [
        "def plot_day(x, y):\n",
        "  plt.scatter(train_features['day'], train_labels, label='Data', alpha=0.3)\n",
        "  plt.plot(x, y, color='k', label='Predictions')\n",
        "  plt.xlabel('day')\n",
        "  plt.ylim([0.2, 0.8])\n",
        "  plt.ylabel('NUM_TRIPS')\n",
        "  plt.legend()\n",
        "\n",
        "  plot_day(x, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ONthTi3Mdgn_"
      },
      "outputs": [],
      "source": [
        "## Looking good, let's try a linear regression model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "WtNRGvBUeIu-",
        "outputId": "784fa59a-ed6e-4eae-b1d3-6ef892040c06"
      },
      "outputs": [],
      "source": [
        "many_input_data = [df_final[\"day\"], df_final[\"temp\"], df_final[\"NUM_COLLISIONS\"]] # create an array of all values for day and all values for NUM_TRIPS in two columns\n",
        "headers = [\"day\", \"temp\", \"NUM_COLLISIONS\"] # declare the titles of our input and output. As you can see day is first and NUM_TRIPS is second and these correspond to the line above\n",
        "df_many_input = pd.concat(many_input_data, axis=1, keys=headers) # Bring these two arrays together to make a new dataframe\n",
        "df_many_input.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8MlU8Uqequr"
      },
      "outputs": [],
      "source": [
        "train_dataset = df_many_input.sample(frac=0.8, random_state=0)\n",
        "test_dataset = df_many_input.drop(train_dataset.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0lqsz7Ket0j"
      },
      "outputs": [],
      "source": [
        "train_features = train_dataset.copy()\n",
        "test_features = test_dataset.copy()\n",
        "\n",
        "train_labels = train_features.pop('NUM_COLLISIONS')\n",
        "test_labels = test_features.pop('NUM_COLLISIONS')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "kSUwgw81e0ZD",
        "outputId": "90728806-55d1-47f3-d31f-72b4235933a0"
      },
      "outputs": [],
      "source": [
        "train_features.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JzfMcI5ue5wj"
      },
      "outputs": [],
      "source": [
        "train_labels = train_labels/scale_factor\n",
        "test_labels = test_labels/scale_factor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NzWeSRke8M4",
        "outputId": "032a29f0-bf3f-4917-ecaa-5cb22e961d34"
      },
      "outputs": [],
      "source": [
        "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
        "normalizer.adapt(np.array(train_features))\n",
        "first = np.array(train_features[:1])\n",
        "\n",
        "with np.printoptions(precision=2, suppress=True):\n",
        "  print('First example:', first)\n",
        "  print()\n",
        "  print('Normalized:', normalizer(first).numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6kLDaW-ae-uQ"
      },
      "outputs": [],
      "source": [
        "linear_model = tf.keras.Sequential([\n",
        "    normalizer,\n",
        "    layers.Dense(units=1)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcSnCC9cfBBN",
        "outputId": "9779eb2c-732a-4d8b-ae86-6daa05ac88ae"
      },
      "outputs": [],
      "source": [
        "linear_model.predict(train_features[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGpR7duvfD3V",
        "outputId": "58349c85-7fc9-426e-9464-f4364342b516"
      },
      "outputs": [],
      "source": [
        "linear_model.layers[1].kernel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9iY4Kt2OfGmI"
      },
      "outputs": [],
      "source": [
        "linear_model.compile(\n",
        "    optimizer=tf.optimizers.Adam(learning_rate=0.1),\n",
        "    loss='mean_absolute_error')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rJTC_6CfI35",
        "outputId": "d4b9f160-3a54-406c-862c-be3c910adae8"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "history = linear_model.fit(\n",
        "    train_features,\n",
        "    train_labels,\n",
        "    epochs=100,\n",
        "    # Suppress logging.\n",
        "    verbose=0,\n",
        "    # Calculate validation results on 20% of the training data.\n",
        "    validation_split = 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "jYDHi78kfOPq",
        "outputId": "900cac3d-9738-45d6-ecd8-8be1c08615d9"
      },
      "outputs": [],
      "source": [
        "plot_loss(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EmejYqKZfSNj"
      },
      "outputs": [],
      "source": [
        "test_results['linear_model'] = linear_model.evaluate(\n",
        "    test_features, test_labels, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "y0EXT-2PfR9B",
        "outputId": "f10aedb4-0c0d-4d2d-c0f5-6886de4d1638"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(test_results, index=['Mean absolute error [NUM_COLLISIONS]']).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tSa4Dk4AgRjU"
      },
      "outputs": [],
      "source": [
        "#Very interesting - day model is better overall, as MSE is lower"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XiJQvlq6hgLz"
      },
      "outputs": [],
      "source": [
        "###DNN Model###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "hjmagsftgVLH",
        "outputId": "46754e34-aec8-4aba-a0e8-c2c55e0c48ff"
      },
      "outputs": [],
      "source": [
        "groups = df_final.groupby('mo') # We group by month as we want to create a legend and make the visualisation clearer using colour.\n",
        "fig, ax = plt.subplots();\n",
        "plt.ylim(0, 4000)\n",
        "for name, group in groups:\n",
        "    plt.plot(group.year, group.NUM_COLLISIONS, marker='o', linestyle='', markersize=4, label=name)\n",
        "\n",
        "plt.legend()\n",
        "ax.axvline(x=0, ymin=0.0, ymax=1.0, color='r')\n",
        "ax.axvline(x=31, ymin=0.0, ymax=1.0, color='r')\n",
        "ax.axvline(x=59, ymin=0.0, ymax=1.0, color='r')\n",
        "ax.axvline(x=90, ymin=0.0, ymax=1.0, color='r')\n",
        "ax.axvline(x=120, ymin=0.0, ymax=1.0, color='r')\n",
        "ax.axvline(x=151, ymin=0.0, ymax=1.0, color='r')\n",
        "ax.axvline(x=181, ymin=0.0, ymax=1.0, color='r')\n",
        "ax.axvline(x=212, ymin=0.0, ymax=1.0, color='r')\n",
        "ax.axvline(x=243, ymin=0.0, ymax=1.0, color='r')\n",
        "ax.axvline(x=273, ymin=0.0, ymax=1.0, color='r')\n",
        "ax.axvline(x=304, ymin=0.0, ymax=1.0, color='r')\n",
        "ax.axvline(x=334, ymin=0.0, ymax=1.0, color='r')\n",
        "ax.axvline(x=365, ymin=0.0, ymax=1.0, color='r')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JL9DBFYukhYG"
      },
      "outputs": [],
      "source": [
        "#Examine March"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "td6_6rL-kjPA",
        "outputId": "2813623b-1257-4a22-a251-2aab56a76c88"
      },
      "outputs": [],
      "source": [
        "df_final_march = df_final[df_final[\"mo\"] == 3]\n",
        "groups = df_final_march.groupby('year') # We group by year as we want to create a legend and make the visualisation clearer using colour.\n",
        "plt.ylim(0, 7000)\n",
        "for name, group in groups:\n",
        "    plt.plot(group.year, group.NUM_COLLISIONS, marker='o', linestyle='', markersize=4, label=name)\n",
        "\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 594
        },
        "id": "rh8jJNiVltmI",
        "outputId": "0d0bf814-c732-4d9d-ebd3-571c8391a7e0"
      },
      "outputs": [],
      "source": [
        "corrMatrix = df_final_march.corr()\n",
        "sn.heatmap(corrMatrix, annot=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "x3a80M7eoJt1",
        "outputId": "6c3875b6-1ed6-4f7e-e154-8958d45d2ddd"
      },
      "outputs": [],
      "source": [
        "#add one hot encoding\n",
        "df_final.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xoH2Avs3oSEA"
      },
      "outputs": [],
      "source": [
        "# One-Hot Encoding for day\n",
        "df_final['da'] = df_final['da'].map({ 1: 'Sunday', 2: 'Monday', 3: 'Tuesday', 4: 'Wednesday', 5: 'Thursday', 6: 'Friday', 7: 'Saturday'})\n",
        "df_final = pd.get_dummies(df_final, columns=['da'], prefix='', prefix_sep='')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qAbj2FBHo4nX"
      },
      "outputs": [],
      "source": [
        "# One-Hot Encoding for month\n",
        "df_final['mo'] = df_final['mo'].map({ 1: 'January', 2: 'February', 3: 'March', 4: 'April', 5: 'May', 6: 'June', 7: 'July', 8: 'August', 9: 'September', 10: 'October', 11: 'November', 12: 'December'})\n",
        "df_final = pd.get_dummies(df_final, columns=['mo'], prefix='', prefix_sep='')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "TadyWyeso_nm",
        "outputId": "24b752bc-bb5a-4bb4-e17e-fffe89ee7874"
      },
      "outputs": [],
      "source": [
        "df_final.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "WQ--sRpZpCfy",
        "outputId": "6d9260c8-67cc-4c28-b0f4-7ddf9e929aab"
      },
      "outputs": [],
      "source": [
        "dnn_many_input_data = [df_final[\"year\"], df_final[\"temp\"], df_final[\"dewp\"], df_final[\"slp\"], df_final[\"visib\"], df_final[\"wdsp\"], df_final[\"gust\"], df_final[\"prcp\"], df_final[\"sndp\"], df_final[\"fog\"], df_final[\"Sunday\"], df_final[\"Monday\"], df_final[\"Tuesday\"], df_final[\"Wednesday\"], df_final[\"Thursday\"], df_final[\"Friday\"], df_final[\"Saturday\"], df_final[\"January\"], df_final[\"February\"], df_final[\"March\"], df_final[\"April\"], df_final[\"May\"], df_final[\"June\"], df_final[\"July\"], df_final[\"August\"], df_final[\"September\"], df_final[\"October\"], df_final[\"November\"], df_final[\"December\"], df_final[\"NUM_COLLISIONS\"]]\n",
        "headers = [\"year\",\"temp\",\"dewp\",\"slp\",\"visib\",\"wdsp\",\"gust\",\"prcp\",\"sndp\",\"fog\",\"Sunday\",\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\",\"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\"July\",\"August\",\"September\",\"October\",\"November\",\"December\",\"NUM_TRIPS\"]\n",
        "df_dnn_many_input = pd.concat(dnn_many_input_data, axis=1, keys=headers)\n",
        "df_dnn_many_input.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pl4J-SI8pNE0"
      },
      "outputs": [],
      "source": [
        "train_dataset = df_dnn_many_input.sample(frac=0.8, random_state=0)\n",
        "test_dataset = df_dnn_many_input.drop(train_dataset.index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scj7fTpkrKVI"
      },
      "source": [
        "***Hit error from here onwards***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "EbHfRv0FpPkO",
        "outputId": "ead3dbd7-bbeb-44b3-c68e-4cba801b2382"
      },
      "outputs": [],
      "source": [
        "train_features = train_dataset.copy()\n",
        "test_features = test_dataset.copy()\n",
        "\n",
        "train_labels = train_features.pop('NUM_COLLISIONS')\n",
        "test_labels = test_features.pop('NUM_COLLISIONS')\n",
        "\n",
        "#Hit error here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zxbjyIbq_KX"
      },
      "outputs": [],
      "source": [
        "# Scale labels\n",
        "\n",
        "train_labels = train_labels/scale_factor\n",
        "test_labels = test_labels/scale_factor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oeh5N1iWrGF5"
      },
      "outputs": [],
      "source": [
        "# put model into function\n",
        "\n",
        "def build_and_compile_model(norm):\n",
        "  model = keras.Sequential([\n",
        "      norm,\n",
        "      layers.Dense(64, activation='relu'),\n",
        "      layers.Dense(64, activation='relu'),\n",
        "      layers.Dense(1)\n",
        "  ])\n",
        "\n",
        "  model.compile(loss='mean_absolute_error',\n",
        "                optimizer=tf.keras.optimizers.Adam(0.001))\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iwqcIWhjrQcP"
      },
      "outputs": [],
      "source": [
        "#normalizer = tf.keras.layers.Normalization(axis=-1)\n",
        "normalizer.adapt(np.array(train_features))\n",
        "first = np.array(train_features[:1])\n",
        "\n",
        "with np.printoptions(precision=2, suppress=True):\n",
        "  print('First example:', first)\n",
        "  print()\n",
        "  print('Normalized:', normalizer(first).numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-KLeK_3rTOJ"
      },
      "outputs": [],
      "source": [
        "#Then make model\n",
        "\n",
        "dnn_model = build_and_compile_model(normalizer)\n",
        "dnn_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96OgY6dNrXcx"
      },
      "outputs": [],
      "source": [
        "#train model\n",
        "%%time\n",
        "history = dnn_model.fit(\n",
        "    train_features,\n",
        "    train_labels,\n",
        "    validation_split=0.2,\n",
        "    verbose=0, epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GCdCnm8trZwa"
      },
      "outputs": [],
      "source": [
        "plot_loss(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-f9eRMOrbrG"
      },
      "outputs": [],
      "source": [
        "#Store results\n",
        "\n",
        "test_results['dnn_model'] = dnn_model.evaluate(test_features, test_labels, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m4PJPdEqrgeg"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(test_results, index=['Mean absolute error [NUM_TRIPS]']).T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_rZ7yUaim4k"
      },
      "source": [
        "# Module 5: Using the outcomes\n",
        "\n",
        "In this section you want to use the test data to test what kind of money you will potentially make.\n",
        "\n",
        "Your company rents cars daily to people in New York City and is struggling in a saturated market. You have noted that you offer a flat rate damage waiver insurance package to all customers and that most customers chose not to take it. This package is something that has the potential to make the company lots of money if marketed properly.\n",
        "\n",
        "At the moment you offer the package for a fee of 30 dollars per day, with only around 30% of all customers taking it. You rent on average 20,000 vehicles per day and therefore this package makes the company 180,000 dollars. The damage caused by collisions costs on average 500 dollars per collision with 8% of customers encountering a collision of some kind resulting in damage. The total costs from damage come to 800,000 dollars, which is covered by the customers' insurance, but around 10% of this is covered by the company due to fradulent behaviour or customers taking the waiver. This results in a profit of around 100,000 dollars per day for the sale of this package alone.\n",
        "\n",
        "This 30 dollars is based on an expected 1,200 collisions per day (based on the maximum).\n",
        "\n",
        "The goal of this investigation is to accurately predict the number of expected collisions on a given day in order to reduce the price of the on-demand package and therefore give value to the customer. Surveys have shown that a competitive price would result in 80% of respondents taking the damage waiver insurance option – but the price must reflect the associated costs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DYKKc89RxkYP"
      },
      "outputs": [],
      "source": [
        "# Import packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Ignore the line under here, this is to suppress a warning\n",
        "pd.options.mode.chained_assignment = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lW0HYBPAxobb",
        "outputId": "547dc13c-cbdc-447f-97c4-b63115d19e97"
      },
      "outputs": [],
      "source": [
        "# Link with your google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0mKRG9Gxn0Jn"
      },
      "outputs": [],
      "source": [
        "df_2019_test_data = pd.read_csv('/content/gdrive/MyDrive/LBD_testdata2019.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tE_OyaT9n6pi"
      },
      "outputs": [],
      "source": [
        "df_2019_test_data = df_2019_test_data.sort_values([\"year\", \"mo\", \"da\"], ascending = (True, True, True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "t5TUv-dgn9iJ",
        "outputId": "ab012574-3a67-4c78-9ef9-bce92ea495ce"
      },
      "outputs": [],
      "source": [
        "df_2019_test_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRseWRNlyAM3",
        "outputId": "5ca14148-0ebf-47b5-85c6-0430fa4b7332"
      },
      "outputs": [],
      "source": [
        "linear_day_predictions = day_model.predict(df_2019_test_data[\"day\"][:90])*scale_factor\n",
        "linear_day_predictions #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 830
        },
        "id": "rjN8BZB8yJsQ",
        "outputId": "994f526b-f98f-4399-9165-a455ccfdb345"
      },
      "outputs": [],
      "source": [
        "#error on pickup data, so used day\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
        "plt.scatter(df_2019_test_data[\"day\"][:90], df_2019_test_data[\"NUM_COLLISIONS\"][:90], c='b', marker='x', label='actual')\n",
        "plt.scatter(df_2019_test_data[\"day\"][:90], linear_day_predictions[:90], c='r', marker='s', label='predication')\n",
        "plt.ylim(0, 8700)\n",
        "plt.legend(loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBtHhrB2zEFz"
      },
      "outputs": [],
      "source": [
        "#Shows somewhat linear increase day by day"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "K3z68L5lzNdN",
        "outputId": "9b3139de-0cb9-4074-808a-fc1b1150e0c3"
      },
      "outputs": [],
      "source": [
        "input_data_multi_linear = [df_2019_test_data[\"day\"][:90], df_2019_test_data[\"temp\"][:90]]\n",
        "headers = [\"day\",\"temp\"]\n",
        "df_input_data_multi_linear = pd.concat(input_data_multi_linear, axis=1, keys=headers)\n",
        "df_input_data_multi_linear"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7BBWwHEzUau",
        "outputId": "e97dee75-110b-4a39-bde7-5faf2b606ccd"
      },
      "outputs": [],
      "source": [
        "df_input_data_multi_linear = pd.concat(input_data_multi_linear, axis=1, keys=headers)\n",
        "linear_multi_predictions = linear_model.predict(df_input_data_multi_linear)*scale_factor\n",
        "linear_multi_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8NzIi67bzYTo",
        "outputId": "d0097960-7087-469f-adaa-39cde0818181"
      },
      "outputs": [],
      "source": [
        "plt.rcParams[\"figure.figsize\"] = (20,20)\n",
        "plt.scatter(df_2019_test_data[\"day\"][:90], df_2019_test_data[\"NUM_COLLISIONS\"][:90], c='b', marker='x', label='actual')\n",
        "plt.scatter(df_2019_test_data[\"day\"][:90], linear_multi_predictions[:90], c='r', marker='s', label='predication')\n",
        "plt.ylim(0, 8700)\n",
        "plt.legend(loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "izDTbb88zoNg"
      },
      "outputs": [],
      "source": [
        "df_2019_test_data_dnn = df_2019_test_data\n",
        "# One-Hot Encoding for day\n",
        "df_2019_test_data_dnn['day'] = df_2019_test_data_dnn['day'].map({ 1: 'Sunday', 2: 'Monday', 3: 'Tuesday', 4: 'Wednesday', 5: 'Thursday', 6: 'Friday', 7: 'Saturday'})\n",
        "df_2019_test_data_dnn = pd.get_dummies(df_2019_test_data_dnn, columns=['day'], prefix='', prefix_sep='')\n",
        "\n",
        "# One-Hot Encoding for month\n",
        "df_2019_test_data_dnn['mo'] = df_2019_test_data['mo'].map({ 1: 'January', 2: 'February', 3: 'March', 4: 'April', 5: 'May', 6: 'June', 7: 'July', 8: 'August', 9: 'September', 10: 'October', 11: 'November', 12: 'December'})\n",
        "df_2019_test_data_dnn = pd.get_dummies(df_2019_test_data_dnn, columns=['mo'], prefix='', prefix_sep='')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "qMo8Fz-Wzt0c",
        "outputId": "ac3cbcfc-42b5-4019-b014-1918f4df2f94"
      },
      "outputs": [],
      "source": [
        "df_2019_test_data_dnn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "9qzPbZFyz13z",
        "outputId": "34d17a94-6db9-44f4-c0e5-5642ca344871"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming df_2019_test_data_dnn and df_2014_test_data_dnn are already defined\n",
        "\n",
        "# Selecting columns from df_2019_test_data_dnn and df_2014_test_data_dnn\n",
        "selected_columns_2019 = df_2019_test_data_dnn[[\"year\", \"temp\", \"dewp\", \"slp\", \"visib\", \"wdsp\", \"gust\", \"prcp\"]]\n",
        "selected_columns_2014 = df_2014_test_data_dnn[[\"sndp\", \"fog\", \"Sunday\", \"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"]]\n",
        "\n",
        "# Concatenating selected columns\n",
        "df_2019_test_data_dnn_cleaned = pd.concat([selected_columns_2019, selected_columns_2014], axis=1)\n",
        "\n",
        "# Optionally, you can rename the columns\n",
        "headers = [\"year\", \"temp\", \"dewp\", \"slp\", \"visib\", \"wdsp\", \"gust\", \"prcp\", \"sndp\", \"fog\", \"Sunday\", \"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"]\n",
        "df_2019_test_data_dnn_cleaned.columns = headers\n",
        "\n",
        "df_2019_test_data_dnn_cleaned.head()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "x57j7i7HiUb4",
        "3zYSCsAvK7Z2"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
